{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d415f0-cef7-4fe5-b8c4-8331e5f6da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import BinaryIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe0ee3-4b7d-45b3-8680-8fec32d1d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./tokenizer/bpe_example.txt', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4696854a-9050-4f74-83f2-3ccb49fe2296",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1d405-efd7-456f-8e51-9ecd04e2c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = f.read(10)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7484a503-7480-4823-bc91-44385a321b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e464d-8409-46e2-aa7b-1bf05d6180a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe(\n",
    "        input_path: str | os.PathLike,\n",
    "        vocab_size: int,\n",
    "        special_tokens: list[str]\n",
    ") -> tuple[dict[int, bytes], list[tuple[bytes, bytes]]]:\n",
    "    path: Path = Path(input_path)\n",
    "    context: str\n",
    "    with path.open('+r'):\n",
    "        \n",
    "    return {}, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5109d-b83a-461f-b0da-44c8f8563e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = './tokenizer/bpe_example.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b1c90-f358-4928-9561-7681dd57a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "path: Path = Path(p)\n",
    "content: str = ''\n",
    "with path.open('+r') as f:\n",
    "    content = f.read()\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf5987a-4aa5-461c-8137-a54396e7c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "content.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68fe751-6dd5-4fd5-9a55-d0cb54044fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "def pretokenizer(content: str, special_tokens: list[str]) -> dict[list[bytes], int]:\n",
    "    matches = re.finditer(PAT, content)\n",
    "    counter = {}\n",
    "    for match in matches:\n",
    "        text = match.group()\n",
    "        counter[text] = counter.get(text, 0) + 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c63ad-9ade-43f1-8503-a1a5589546ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretokenizer(content, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7b3dd-dc79-4c9b-be41-1530ea56f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_tokens(content: str, special_tokens: list[str]) -> list[str]:\n",
    "    pattern = '|'.join(re.escape(d) for d in special_tokens)\n",
    "    return re.split(pattern, content)\n",
    "\n",
    "\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "\n",
    "def pretokenizer(content: str, special_tokens: list[str]) -> dict[list[bytes], int]:\n",
    "    docs = remove_special_tokens(content, special_tokens)\n",
    "    counter = {}\n",
    "    for doc in docs:\n",
    "        matches = re.finditer(PAT, doc)\n",
    "\n",
    "        for match in matches:\n",
    "            text = tuple(match.group().encode('utf8'))\n",
    "            counter[text] = counter.get(text, 0) + 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951fe4e-da91-4cb3-9b57-e2dd78fbc4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/TinyStoriesV2-GPT4-valid.txt')\n",
    "with path.open('+r') as f:\n",
    "    content = f.read()\n",
    "    print(pretokenizer(content, ['<|endoftext|>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6346a-99e9-495c-96a7-9f8d9bba409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2ae5a-f6e8-4d73-901f-247ad3bc5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a416224-4424-4cb1-90b9-17c27b34d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(256):\n",
    "    print(bytes([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f019c0-5639-4bbb-85d5-d4193529d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vocab(special_tokens: list[str]) -> dict[int, bytes]:\n",
    "    vocab = {}\n",
    "    for i in range(256):\n",
    "        vocab[i] = bytes([i])\n",
    "    for st in special_tokens:\n",
    "        idx = len(vocab)\n",
    "        vocab[idx] = st.encode('utf8')\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26789ef-760d-4691-88b5-849f8e8bdd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_vocab(['<|endoftext|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837cb07-dc26-4999-b9af-fb12a2d5aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_bp(pretokenized_count: dict[tuple[bytes], int]):\n",
    "    # Count byte pairs\n",
    "    bp_counter = {}\n",
    "    for bytes_tuple, count in pretokenized_count.items():\n",
    "        for i in range(len(bytes_tuple) - 1):\n",
    "            bp = (bytes_tuple[i], bytes_tuple[i+1])\n",
    "            bp_counter[bp] = bp_counter.get(bp, 0) + count\n",
    "    max_bp, max_count = (bytes([0]), bytes([0])), 0\n",
    "    for bp, bp_count in bp_counter.items():\n",
    "        if bp_count > max_count:\n",
    "            max_bp = bp\n",
    "            max_count = bp_count\n",
    "        if bp_count == max_count and bp > max_bp:\n",
    "            max_bp = bp\n",
    "            max_count = bp_count\n",
    "    return max_bp, max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c00c4b-c2f2-4fe5-83b2-e3c68ad156a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretokenized_count():\n",
    "    path = Path('data/TinyStoriesV2-GPT4-valid.txt')\n",
    "    with path.open('+r') as f:\n",
    "        content = f.read()\n",
    "        return pretokenizer(content, ['<|endoftext|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456d741-9dbf-495b-bd9a-d3413da5443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretokenized_count = get_pretokenized_count()\n",
    "max_bp, max_count = find_max_bp(pretokenized_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fae080-3ace-4fe7-a53f-e8b2bf2af4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c797d-81a6-428f-8887-c92e9717753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = b'\\x01\\x02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c7b9e3-862d-442d-88ee-b15962381604",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b372b5-45dd-49bb-81ea-21698facc3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes(max_bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddccc2c0-8fcb-406c-b313-29cf77c20bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c9279-fb9d-4014-bee3-fcc03f9c13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/tinystory_train_vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ca8855-96ab-4b3d-9fd3-50356eaf34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/tinystory_train_merges.pkl', 'rb') as f:\n",
    "    merges = pickle.load(f)\n",
    "\n",
    "print(len(merges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a897a19c-64b7-4a6f-839f-e0b58045af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange, einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5654291a-4e6e-4bd6-a96d-072a888df337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0,   1,   2,   3,   4],\n",
       "          [  5,   6,   7,   8,   9],\n",
       "          [ 10,  11,  12,  13,  14],\n",
       "          [ 15,  16,  17,  18,  19]],\n",
       "\n",
       "         [[ 20,  21,  22,  23,  24],\n",
       "          [ 25,  26,  27,  28,  29],\n",
       "          [ 30,  31,  32,  33,  34],\n",
       "          [ 35,  36,  37,  38,  39]],\n",
       "\n",
       "         [[ 40,  41,  42,  43,  44],\n",
       "          [ 45,  46,  47,  48,  49],\n",
       "          [ 50,  51,  52,  53,  54],\n",
       "          [ 55,  56,  57,  58,  59]]],\n",
       "\n",
       "\n",
       "        [[[ 60,  61,  62,  63,  64],\n",
       "          [ 65,  66,  67,  68,  69],\n",
       "          [ 70,  71,  72,  73,  74],\n",
       "          [ 75,  76,  77,  78,  79]],\n",
       "\n",
       "         [[ 80,  81,  82,  83,  84],\n",
       "          [ 85,  86,  87,  88,  89],\n",
       "          [ 90,  91,  92,  93,  94],\n",
       "          [ 95,  96,  97,  98,  99]],\n",
       "\n",
       "         [[100, 101, 102, 103, 104],\n",
       "          [105, 106, 107, 108, 109],\n",
       "          [110, 111, 112, 113, 114],\n",
       "          [115, 116, 117, 118, 119]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(120).reshape([2,3,4,5])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3782b868-312a-4296-af10-4ccf29490065",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (int, int, int, int), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: transpose() received an invalid combination of arguments - got (int, int, int, int), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n"
     ]
    }
   ],
   "source": [
    "x.transpose(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3656f24-6125-499d-bcd9-516977e12735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0,   1,   2,   3,   4],\n",
       "          [ 20,  21,  22,  23,  24],\n",
       "          [ 40,  41,  42,  43,  44]],\n",
       "\n",
       "         [[  5,   6,   7,   8,   9],\n",
       "          [ 25,  26,  27,  28,  29],\n",
       "          [ 45,  46,  47,  48,  49]],\n",
       "\n",
       "         [[ 10,  11,  12,  13,  14],\n",
       "          [ 30,  31,  32,  33,  34],\n",
       "          [ 50,  51,  52,  53,  54]],\n",
       "\n",
       "         [[ 15,  16,  17,  18,  19],\n",
       "          [ 35,  36,  37,  38,  39],\n",
       "          [ 55,  56,  57,  58,  59]]],\n",
       "\n",
       "\n",
       "        [[[ 60,  61,  62,  63,  64],\n",
       "          [ 80,  81,  82,  83,  84],\n",
       "          [100, 101, 102, 103, 104]],\n",
       "\n",
       "         [[ 65,  66,  67,  68,  69],\n",
       "          [ 85,  86,  87,  88,  89],\n",
       "          [105, 106, 107, 108, 109]],\n",
       "\n",
       "         [[ 70,  71,  72,  73,  74],\n",
       "          [ 90,  91,  92,  93,  94],\n",
       "          [110, 111, 112, 113, 114]],\n",
       "\n",
       "         [[ 75,  76,  77,  78,  79],\n",
       "          [ 95,  96,  97,  98,  99],\n",
       "          [115, 116, 117, 118, 119]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(x, 'b h w c -> b w h c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc613e3d-d4da-4a27-a9e2-1d02cc463656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   1,   2,   3,   4],\n",
       "         [  5,   6,   7,   8,   9],\n",
       "         [ 10,  11,  12,  13,  14],\n",
       "         [ 15,  16,  17,  18,  19],\n",
       "         [ 20,  21,  22,  23,  24],\n",
       "         [ 25,  26,  27,  28,  29],\n",
       "         [ 30,  31,  32,  33,  34],\n",
       "         [ 35,  36,  37,  38,  39],\n",
       "         [ 40,  41,  42,  43,  44],\n",
       "         [ 45,  46,  47,  48,  49],\n",
       "         [ 50,  51,  52,  53,  54],\n",
       "         [ 55,  56,  57,  58,  59]],\n",
       "\n",
       "        [[ 60,  61,  62,  63,  64],\n",
       "         [ 65,  66,  67,  68,  69],\n",
       "         [ 70,  71,  72,  73,  74],\n",
       "         [ 75,  76,  77,  78,  79],\n",
       "         [ 80,  81,  82,  83,  84],\n",
       "         [ 85,  86,  87,  88,  89],\n",
       "         [ 90,  91,  92,  93,  94],\n",
       "         [ 95,  96,  97,  98,  99],\n",
       "         [100, 101, 102, 103, 104],\n",
       "         [105, 106, 107, 108, 109],\n",
       "         [110, 111, 112, 113, 114],\n",
       "         [115, 116, 117, 118, 119]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(x, 'b h w c -> b (h w) c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ebdc51-80d3-4326-9368-bbd08d0a40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99e0328e-5654-4036-8895-dcc2173f0dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0202,  1.1880,  0.3029,  1.0919, -0.4739],\n",
      "        [-0.4320, -0.4433, -2.1584, -0.0684, -0.7498],\n",
      "        [-0.3768,  0.4320,  0.0348,  1.3644,  0.8986],\n",
      "        [ 0.7867,  0.1175, -1.3295,  0.8390,  0.4578]])\n",
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 5)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb08664c-7d16-417b-a825-16fe49628f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([[ 1.1880],\n",
      "        [-0.0684],\n",
      "        [ 1.3644],\n",
      "        [ 0.8390]]),\n",
      "indices=tensor([[1],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3]]))\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "m = x.max(dim=1, keepdim=True)\n",
    "print(m)\n",
    "print(m.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "294a0906-3a4c-4f66-9fd7-824863a983a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "select() received an invalid combination of arguments - got (int), but expected one of:\n * (name dim, int index)\n * (int dim, int index)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: select() received an invalid combination of arguments - got (int), but expected one of:\n * (name dim, int index)\n * (int dim, int index)\n"
     ]
    }
   ],
   "source": [
    "x.select(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
